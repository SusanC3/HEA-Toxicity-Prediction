
loading data
ToxicityRegressor(
  (layer_1): Linear(in_features=801, out_features=16, bias=True)
  (layer_2): Linear(in_features=16, out_features=32, bias=True)
  (layer_3): Linear(in_features=32, out_features=16, bias=True)
  (layer_out): Linear(in_features=16, out_features=229432, bias=True)
  (relu): ReLU()
)
Begin training
fold 1
loss item: 0.09462179243564606
loss item: 0.09494287520647049
loss item: 0.11686626076698303
loss item: 0.10818619281053543
loss item: 0.10443908721208572
loss item: 0.08741825073957443
loss item: 0.7440396547317505
loss item: 0.8192431330680847
test loss 0.2712196558713913
loss item: 1.2473835945129395
loss item: 0.0788385272026062
loss item: 3.2762949466705322
loss item: 0.1407068520784378
loss item: 1.0507299900054932
loss item: 1.0763434171676636
loss item: 0.1283876746892929
loss item: 0.7989813089370728
loss item: 0.14869074523448944
loss item: 0.07700782269239426
loss item: 0.7260856628417969
loss item: 0.0865364596247673
loss item: 2.8797004222869873
loss item: 1.5132356882095337
loss item: 0.10721193253993988
loss item: 0.3792438805103302
loss item: 0.06792478263378143
loss item: 1.942885398864746
loss item: 0.9612125158309937
loss item: 0.6177875995635986
loss item: 0.08064750581979752
loss item: 0.0820063129067421
loss item: 0.08045204728841782
loss item: 0.09615757316350937
loss item: 0.5630220770835876
loss item: 0.10970348864793777
loss item: 0.073509581387043
loss item: 0.6552750468254089
loss item: 0.06373900175094604
loss item: 0.7752842307090759
loss item: 0.6711797714233398
loss item: 0.06582721322774887
loss item: 0.08345465362071991
loss item: 0.6473090052604675
loss item: 0.06836194545030594
loss item: 0.2331835776567459
loss item: 6.316991806030273
loss item: 0.08219493925571442
loss item: 0.7532883882522583
loss item: 0.07962522655725479
loss item: 0.09153386205434799
loss item: 0.8327703475952148
loss item: 0.07221034914255142
loss item: 0.08810583502054214
loss item: 0.08680441975593567
loss item: 0.6396618485450745
loss item: 0.08344944566488266
loss item: 0.08279291540384293
loss item: 3.145029067993164
loss item: 0.09503413736820221
loss item: 0.07977334409952164
loss item: 2.3419926166534424
loss item: 0.0666961520910263
loss item: 2.0612313747406006
loss item: 0.9981613755226135
loss item: 0.07436050474643707
loss item: 0.1006978452205658
loss item: 2.359259605407715
loss item: 1.1880701780319214
loss item: 0.07232710719108582
loss item: 0.07627061754465103
loss item: 0.08122744411230087
loss item: 0.27887842059135437
loss item: 0.931486964225769
loss item: 0.10918300598859787
loss item: 0.06815848499536514
loss item: 0.6371569633483887
loss item: 0.8244889974594116
loss item: 4.143157958984375
loss item: 0.8273694515228271
loss item: 0.6420177221298218
loss item: 0.06066421791911125
train loss 0.7239781277150743
> /mnt/c/Users/susan/git/HEA-Toxicity-Prediction/runner.py(147)<module>()
